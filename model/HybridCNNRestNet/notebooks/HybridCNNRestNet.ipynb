{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04cedce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T15:38:50.259111Z",
     "iopub.status.busy": "2025-12-14T15:38:50.258762Z",
     "iopub.status.idle": "2025-12-14T15:39:01.508576Z",
     "shell.execute_reply": "2025-12-14T15:39:01.507620Z"
    },
    "papermill": {
     "duration": 11.255311,
     "end_time": "2025-12-14T15:39:01.509962",
     "exception": false,
     "start_time": "2025-12-14T15:38:50.254651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import & Config\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "\n",
    "# Cấu hình thiết bị\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Cấu hình đường dẫn\n",
    "INPUT_EMBED_DIR = \"/kaggle/input/cafa6-t5-embeddings\"\n",
    "\n",
    "CONFIG = {\n",
    "    \"num_labels\": 1500,\n",
    "    \"batch_size\": 128,\n",
    "    \"lr\": 0.001,\n",
    "    \"epochs\": 20, # Tăng epoch lên vì chạy nhanh\n",
    "    \"paths\": {\n",
    "        # File Embedding có sẵn\n",
    "        \"train_embeds\": f\"{INPUT_EMBED_DIR}/train_embeddings_esm2.npy\",\n",
    "        \"train_ids\":    f\"{INPUT_EMBED_DIR}/train_ids_esm2.npy\",\n",
    "        \"test_embeds\":  f\"{INPUT_EMBED_DIR}/test_embeddings_esm2.npy\",\n",
    "        \"test_ids\":     f\"{INPUT_EMBED_DIR}/test_ids_esm2.npy\",\n",
    "        \n",
    "        # File Labels gốc của cuộc thi\n",
    "        \"train_terms\": \"/kaggle/input/cafa-6-protein-function-prediction/Train/train_terms.tsv\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6565be83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T15:39:01.516147Z",
     "iopub.status.busy": "2025-12-14T15:39:01.515740Z",
     "iopub.status.idle": "2025-12-14T15:39:13.478085Z",
     "shell.execute_reply": "2025-12-14T15:39:13.477123Z"
    },
    "papermill": {
     "duration": 11.966778,
     "end_time": "2025-12-14T15:39:13.479589",
     "exception": false,
     "start_time": "2025-12-14T15:39:01.512811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from disk...\n",
      "--- Data Loaded ---\n",
      "Train shape: (82404, 1280)\n",
      "Test shape:  (224309, 1280)\n",
      "Embedding Dimension detected: 1280\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load Embeddings\n",
    "print(\"Loading embeddings from disk...\")\n",
    "\n",
    "# Load Train\n",
    "train_embeds = np.load(CONFIG['paths']['train_embeds'])\n",
    "train_ids = np.load(CONFIG['paths']['train_ids'], allow_pickle=True)\n",
    "\n",
    "# Load Test\n",
    "test_embeds = np.load(CONFIG['paths']['test_embeds'])\n",
    "test_ids = np.load(CONFIG['paths']['test_ids'], allow_pickle=True)\n",
    "\n",
    "# Tự động cập nhật kích thước đầu vào (Input Dimension)\n",
    "EMBED_DIM = train_embeds.shape[1]\n",
    "\n",
    "print(f\"--- Data Loaded ---\")\n",
    "print(f\"Train shape: {train_embeds.shape}\")\n",
    "print(f\"Test shape:  {test_embeds.shape}\")\n",
    "print(f\"Embedding Dimension detected: {EMBED_DIM}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5d881e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T15:39:13.485426Z",
     "iopub.status.busy": "2025-12-14T15:39:13.485146Z",
     "iopub.status.idle": "2025-12-14T15:39:14.955630Z",
     "shell.execute_reply": "2025-12-14T15:39:14.954934Z"
    },
    "papermill": {
     "duration": 1.47501,
     "end_time": "2025-12-14T15:39:14.956905",
     "exception": false,
     "start_time": "2025-12-14T15:39:13.481895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing Targets & Fixing ID Format ---\n",
      "[DEBUG] ID gốc: sp|A0A0C5B5G6|MOTSC_HUMAN\n",
      "[DEBUG] ID sau khi sửa: A0A0C5B5G6\n",
      "Số lượng dòng khớp được: 342098\n",
      "Đang tạo ma trận nhãn...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 342098/342098 [00:00<00:00, 592899.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ THÀNH CÔNG! Tổng số nhãn dương: 342098.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 3: Prepare Targets\n",
    "import gc\n",
    "\n",
    "print(\"--- Processing Targets & Fixing ID Format ---\")\n",
    "\n",
    "# 1. Load dữ liệu\n",
    "train_terms = pd.read_csv(CONFIG['paths']['train_terms'], sep=\"\\t\")\n",
    "train_ids = np.load(CONFIG['paths']['train_ids'], allow_pickle=True)\n",
    "\n",
    "def clean_id(pid):\n",
    "    # Chuyển bytes sang string (nếu cần)\n",
    "    if isinstance(pid, bytes):\n",
    "        pid = pid.decode('utf-8')\n",
    "    pid_str = str(pid).strip()\n",
    "    \n",
    "    # Logic tách chuỗi\n",
    "    # Tách bằng dấu gạch đứng '|' và lấy phần tử thứ 2 (index 1)\n",
    "    parts = pid_str.split('|')\n",
    "    if len(parts) > 1:\n",
    "        return parts[1] # Lấy mã ở giữa\n",
    "    return pid_str # Trả về nguyên gốc nếu không tìm thấy dấu |\n",
    "\n",
    "# Áp dụng hàm sửa lỗi\n",
    "train_ids_clean = [clean_id(pid) for pid in train_ids]\n",
    "\n",
    "print(f\"[DEBUG] ID gốc: {train_ids[0]}\")\n",
    "print(f\"[DEBUG] ID sau khi sửa: {train_ids_clean[0]}\") # Mong đợi: A0A0C5B5G6\n",
    "\n",
    "# Tạo map\n",
    "id_map = {pid: i for i, pid in enumerate(train_ids_clean)}\n",
    "\n",
    "# 2. Chọn Top Labels\n",
    "top_terms = train_terms['term'].value_counts().index[:CONFIG['num_labels']]\n",
    "term_to_idx = {term: i for i, term in enumerate(top_terms)}\n",
    "\n",
    "# 3. Tạo ma trận Targets\n",
    "num_samples = len(train_ids)\n",
    "labels_matrix = np.zeros((num_samples, CONFIG['num_labels']), dtype=np.float32)\n",
    "\n",
    "# Lọc dữ liệu\n",
    "train_terms['EntryID'] = train_terms['EntryID'].astype(str).str.strip()\n",
    "filtered_terms = train_terms[\n",
    "    (train_terms['EntryID'].isin(id_map)) & \n",
    "    (train_terms['term'].isin(top_terms))\n",
    "]\n",
    "\n",
    "print(f\"Số lượng dòng khớp được: {len(filtered_terms)}\")\n",
    "\n",
    "if len(filtered_terms) == 0:\n",
    "    print(\"Lỗi, vui lòng kiểm tra lại logic cắt chuỗi.\")\n",
    "else:\n",
    "    # Điền số 1 vào ma trận\n",
    "    print(\"Đang tạo ma trận nhãn...\")\n",
    "    for pid, term in tqdm(zip(filtered_terms['EntryID'], filtered_terms['term']), total=len(filtered_terms)):\n",
    "        row_idx = id_map[pid]\n",
    "        col_idx = term_to_idx[term]\n",
    "        labels_matrix[row_idx, col_idx] = 1.0\n",
    "        \n",
    "    print(f\"Tổng số nhãn dương: {labels_matrix.sum()}\")\n",
    "\n",
    "# Dọn dẹp\n",
    "del train_terms, filtered_terms, train_ids_clean\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1386b69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T15:39:14.964508Z",
     "iopub.status.busy": "2025-12-14T15:39:14.964237Z",
     "iopub.status.idle": "2025-12-14T15:39:14.978853Z",
     "shell.execute_reply": "2025-12-14T15:39:14.978187Z"
    },
    "papermill": {
     "duration": 0.01994,
     "end_time": "2025-12-14T15:39:14.979994",
     "exception": false,
     "start_time": "2025-12-14T15:39:14.960054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cell 4: Hybrid CNN-ResNet Model\n",
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, embeddings, targets=None, ids=None):\n",
    "        self.embeddings = embeddings\n",
    "        self.targets = targets\n",
    "        self.ids = ids\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.embeddings)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        embed = torch.tensor(self.embeddings[idx], dtype=torch.float32)\n",
    "        if self.targets is not None:\n",
    "            target = torch.tensor(self.targets[idx], dtype=torch.float32)\n",
    "            return embed, target\n",
    "        return embed, self.ids[idx]\n",
    "\n",
    "# Block phụ trợ\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channel, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        b, c = x.size()\n",
    "        y = x.view(b, c, 1)\n",
    "        y = self.avg_pool(y).view(b, c)\n",
    "        y = self.fc(y)\n",
    "        return x * y\n",
    "\n",
    "class AdvancedResBlock(nn.Module):\n",
    "    def __init__(self, in_features, out_features, dropout_rate=0.25):\n",
    "        super(AdvancedResBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(in_features, out_features),\n",
    "            nn.BatchNorm1d(out_features),\n",
    "            nn.Mish(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(out_features, out_features),\n",
    "            nn.BatchNorm1d(out_features),\n",
    "            nn.Mish(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        self.se = SEBlock(out_features)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_features != out_features:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Linear(in_features, out_features),\n",
    "                nn.BatchNorm1d(out_features)\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        return self.se(self.block(x)) + self.shortcut(x)\n",
    "\n",
    "# Hybrid Model chính\n",
    "class HybridSystem(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(HybridSystem, self).__init__()\n",
    "        \n",
    "        # Nhánh 1: 1D-CNN \n",
    "        # Input shape giả lập: (Batch, 1, 1280)\n",
    "        self.cnn_branch = nn.Sequential(\n",
    "            nn.Conv1d(1, 32, kernel_size=11, padding=5), # Quét cửa sổ lớn\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Mish(),\n",
    "            nn.MaxPool1d(2),\n",
    "            \n",
    "            nn.Conv1d(32, 64, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Mish(),\n",
    "            nn.MaxPool1d(2),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * (input_dim // 4), 512), # Thu gọn về 512 đặc trưng\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Mish(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        \n",
    "        # Nhánh 2: Deep SE-ResNet\n",
    "        self.resnet_branch = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Mish(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            AdvancedResBlock(1024, 1024),\n",
    "            AdvancedResBlock(1024, 512),\n",
    "        ) # Output: 512 đặc trưng\n",
    "        \n",
    "        # Kết hợp\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(512 + 512, 1024), # 512 từ CNN + 512 từ ResNet\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Mish(),\n",
    "            nn.Dropout(0.4)\n",
    "        )\n",
    "        \n",
    "        # Multi-Sample Dropout\n",
    "        # Tạo 5 dropout khác nhau để dự đoán 5 lần và lấy trung bình\n",
    "        self.dropouts = nn.ModuleList([nn.Dropout(0.5) for _ in range(5)])\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1. Chạy nhánh CNN (cần reshape thành 3D tensor: batch, channels, length)\n",
    "        x_cnn = x.unsqueeze(1)\n",
    "        out_cnn = self.cnn_branch(x_cnn)\n",
    "        \n",
    "        # 2. Chạy nhánh ResNet\n",
    "        out_res = self.resnet_branch(x)\n",
    "        \n",
    "        # 3. Gộp lại\n",
    "        combined = torch.cat([out_cnn, out_res], dim=1)\n",
    "        features = self.fusion(combined)\n",
    "        \n",
    "        # 4. Multi-Sample Dropout Output\n",
    "        # Tính toán output qua 5 lớp dropout khác nhau rồi cộng lại\n",
    "        output = torch.zeros(features.size(0), self.fc.out_features).to(features.device)\n",
    "        for dropout in self.dropouts:\n",
    "            output += self.fc(dropout(features))\n",
    "        \n",
    "        return output / len(self.dropouts) # Lấy trung bình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f156714d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T15:39:14.986862Z",
     "iopub.status.busy": "2025-12-14T15:39:14.986627Z",
     "iopub.status.idle": "2025-12-14T15:57:37.659375Z",
     "shell.execute_reply": "2025-12-14T15:57:37.658432Z"
    },
    "papermill": {
     "duration": 1102.678013,
     "end_time": "2025-12-14T15:57:37.660871",
     "exception": false,
     "start_time": "2025-12-14T15:39:14.982858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- START TRAINING HYBRID SYSTEM (5 FOLDS) ---\n",
      "\n",
      ">>> FOLD 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Best Loss: 0.00335\n",
      "\n",
      ">>> FOLD 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 Best Loss: 0.00331\n",
      "\n",
      ">>> FOLD 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Best Loss: 0.00336\n",
      "\n",
      ">>> FOLD 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Best Loss: 0.00336\n",
      "\n",
      ">>> FOLD 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Best Loss: 0.00337\n",
      "\n",
      "--- TRAINING FINISHED --- Avg Loss: 0.00335\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Training Hybrid Model (5-Fold)\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.optim.lr_scheduler import OneCycleLR \n",
    "\n",
    "# Cấu hình Hybrid Model\n",
    "N_FOLDS = 5\n",
    "EPOCHS_PER_FOLD = 18 # Tăng thêm epoch\n",
    "LR = 0.0015\n",
    "BATCH_SIZE = 200 # Giảm nhẹ batch size vì model nặng hơn\n",
    "\n",
    "# Focal Loss \n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, logits=True, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.logits = logits\n",
    "        self.reduce = reduce\n",
    "        self.bce = nn.BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        if self.logits: bce_loss = self.bce(inputs, targets)\n",
    "        else: bce_loss = nn.functional.binary_cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-bce_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * bce_loss\n",
    "        if self.reduce: return torch.mean(F_loss)\n",
    "        else: return F_loss\n",
    "\n",
    "kfold = KFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "print(f\"\\n--- START TRAINING HYBRID SYSTEM ({N_FOLDS} FOLDS) ---\")\n",
    "\n",
    "fold_metrics = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(train_embeds, labels_matrix)):\n",
    "    print(f\"\\n>>> FOLD {fold+1}/{N_FOLDS}\")\n",
    "    \n",
    "    X_train, X_val = train_embeds[train_idx], train_embeds[val_idx]\n",
    "    y_train, y_val = labels_matrix[train_idx], labels_matrix[val_idx]\n",
    "    \n",
    "    train_dataset = ProteinDataset(X_train, y_train)\n",
    "    val_dataset = ProteinDataset(X_val, y_val)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    # Init Hybrid Model\n",
    "    model = HybridSystem(input_dim=EMBED_DIM, num_classes=CONFIG['num_labels']).to(DEVICE)\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-2)\n",
    "    criterion = FocalLoss(gamma=2.0)\n",
    "    \n",
    "    # OneCycleLR\n",
    "    scheduler = OneCycleLR(optimizer, max_lr=LR, steps_per_epoch=len(train_loader), epochs=EPOCHS_PER_FOLD, pct_start=0.3)\n",
    "    \n",
    "    best_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(EPOCHS_PER_FOLD):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for embeds, targets in tqdm(train_loader, desc=f\"Ep {epoch+1}\", leave=False):\n",
    "            embeds, targets = embeds.to(DEVICE), targets.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(embeds)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step() # Step sau mỗi batch với OneCycleLR\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for embeds, targets in val_loader:\n",
    "                embeds, targets = embeds.to(DEVICE), targets.to(DEVICE)\n",
    "                outputs = model(embeds)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), f\"model_fold_{fold}.pth\")\n",
    "            \n",
    "    print(f\"Fold {fold+1} Best Loss: {best_loss:.5f}\")\n",
    "    fold_metrics.append(best_loss)\n",
    "\n",
    "print(f\"\\n--- TRAINING FINISHED --- Avg Loss: {np.mean(fold_metrics):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8189626f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T15:57:38.457652Z",
     "iopub.status.busy": "2025-12-14T15:57:38.456772Z",
     "iopub.status.idle": "2025-12-14T15:58:54.204253Z",
     "shell.execute_reply": "2025-12-14T15:58:54.203204Z"
    },
    "papermill": {
     "duration": 76.146933,
     "end_time": "2025-12-14T15:58:54.205786",
     "exception": false,
     "start_time": "2025-12-14T15:57:38.058853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Generating Predictions (Hybrid System) ---\n",
      "Re-creating index mapping...\n",
      "Loaded 5 Hybrid models.\n",
      "Inference... Threshold=0.015, Top-K=75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 877/877 [01:14<00:00, 11.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Submission saved to submission.tsv successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Ensemble Prediction\n",
    "import gc\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. Khôi phục mapping\n",
    "print(\"Re-creating index mapping...\")\n",
    "df_terms = pd.read_csv(CONFIG['paths']['train_terms'], sep=\"\\t\")\n",
    "top_terms = df_terms['term'].value_counts().index[:CONFIG['num_labels']]\n",
    "idx_to_term = {i: term for i, term in enumerate(top_terms)}\n",
    "del df_terms, top_terms\n",
    "gc.collect()\n",
    "\n",
    "# 2. Setup Data Loader\n",
    "BATCH_SIZE = 256\n",
    "test_dataset_final = ProteinDataset(test_embeds, ids=test_ids)\n",
    "test_loader_final = DataLoader(test_dataset_final, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# 3. Load Models\n",
    "models = []\n",
    "for fold in range(N_FOLDS):\n",
    "    # Dùng đúng class HybridSystem\n",
    "    model = HybridSystem(input_dim=EMBED_DIM, num_classes=CONFIG['num_labels']).to(DEVICE)\n",
    "    model.load_state_dict(torch.load(f\"model_fold_{fold}.pth\"))\n",
    "    model.eval()\n",
    "    models.append(model)\n",
    "print(f\"Loaded {len(models)} Hybrid models.\")\n",
    "\n",
    "# 4. Prediction\n",
    "THRESHOLD = 0.015 \n",
    "TOP_K = 75       \n",
    "output_file = \"submission.tsv\"\n",
    "\n",
    "print(f\"Inference... Threshold={THRESHOLD}, Top-K={TOP_K}\")\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    with torch.no_grad():\n",
    "        for step, (embeds, batch_ids) in enumerate(tqdm(test_loader_final)):\n",
    "            embeds = embeds.to(DEVICE)\n",
    "            \n",
    "            avg_probs = None\n",
    "            for model in models:\n",
    "                logits = model(embeds)\n",
    "                probs = torch.sigmoid(logits)\n",
    "                if avg_probs is None: avg_probs = probs\n",
    "                else: avg_probs += probs\n",
    "            \n",
    "            avg_probs /= len(models)\n",
    "            avg_probs = avg_probs.cpu().numpy()\n",
    "            \n",
    "            batch_lines = []\n",
    "            for i, pid in enumerate(batch_ids):\n",
    "                row_probs = avg_probs[i]\n",
    "                idx_candidates = np.where(row_probs > THRESHOLD)[0]\n",
    "                \n",
    "                if len(idx_candidates) > TOP_K:\n",
    "                    candidate_probs = row_probs[idx_candidates]\n",
    "                    final_indices = idx_candidates[np.argsort(candidate_probs)[-TOP_K:]]\n",
    "                else:\n",
    "                    final_indices = idx_candidates\n",
    "                \n",
    "                for idx in final_indices:\n",
    "                    batch_lines.append(f\"{pid}\\t{idx_to_term[idx]}\\t{row_probs[idx]:.3f}\\n\")\n",
    "            \n",
    "            f.writelines(batch_lines)\n",
    "            del batch_lines, avg_probs, embeds\n",
    "            if step % 50 == 0: gc.collect()\n",
    "\n",
    "print(f\"Submission saved to {output_file}!\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 14875579,
     "sourceId": 116062,
     "sourceType": "competition"
    },
    {
     "datasetId": 8992374,
     "sourceId": 14115963,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1213.153991,
   "end_time": "2025-12-14T15:58:58.030741",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-14T15:38:44.876750",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
